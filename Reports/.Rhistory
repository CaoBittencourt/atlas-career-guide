labels = scales::percent_format()
, limits = c(0,1)
) +
# Legends
guides(
size = 'none'
, color = guide_legend(
override.aes = list(size = 4)
)
) +
# Titles
labs(
title = 'Engineering Skills and Compensation (2021)'
, x = 'Annual Compensation (U$)'
, y = 'Level of Engineering Skills (%)'
, color = 'Level of Education'
) +
# Theme
ggthemes::scale_color_calc() +
ggthemes::theme_tufte()
df_occupations %>%
ggplot(aes(
y = engineering_and_technology.l
, x = annual_wage_2021
, size = annual_wage_2021
)) +
geom_point(aes(
color = entry_level_education
)
, alpha = 0.5
) +
geom_smooth(
method = 'lm'
, color = 'black'
, size = 1.29
) +
# Scale formatting
scale_x_continuous(
labels = scales::dollar_format()
) +
scale_y_continuous(
labels = scales::percent_format()
, limits = c(0,1)
) +
# Legends
guides(
size = 'none'
, color = guide_legend(
override.aes = list(size = 4)
)
) +
# Titles
labs(
title = 'Engineering Skills and Compensation (2021)'
, x = 'Annual Compensation (U$)'
, y = 'Level of Engineering Skills (%)'
, color = 'Level of Education'
) +
# Theme
ggthemes::scale_color_economist() +
ggthemes::theme_tufte()
df_occupations %>%
ggplot(aes(
y = engineering_and_technology.l
, x = annual_wage_2021
, size = annual_wage_2021
)) +
geom_point(aes(
color = entry_level_education
)
, alpha = 0.5
) +
geom_smooth(
method = 'lm'
, color = 'black'
, size = 1.29
) +
# Scale formatting
scale_x_continuous(
labels = scales::dollar_format()
) +
scale_y_continuous(
labels = scales::percent_format()
, limits = c(0,1)
) +
# Legends
guides(
size = 'none'
, color = guide_legend(
override.aes = list(size = 4)
)
) +
# Titles
labs(
title = 'Engineering Skills and Compensation (2021)'
, x = 'Annual Compensation (U$)'
, y = 'Level of Engineering Skills (%)'
, color = 'Level of Education'
) +
# Theme
ggthemes::scale_color_few() +
ggthemes::theme_tufte()
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(message = F)
pkg <- c(
'FNN' #Fast K-NN Algorithm (faster than the 'class' package)
, 'jsonify' #Work with JSON (faster than jsonlite)
, 'tidyverse', 'glue' #Data wrangling
, 'tinytex' #LaTeX
# , 'kableExtra' #LaTeX
)
# Activate / install packages
lapply(pkg, function(x)
if(!require(x, character.only = T))
{install.packages(x); require(x)})
# Install TinyTex
if(!tinytex::is_tinytex()){
tinytex::install_tinytex()
}
# Increase buffer size
# Sys.setenv("VROOM_CONNECTION_SIZE" = 10000000)
# Package citation
# lapply(pkg, function(x)
#   {citation(package = x)})
df_KNN.output %>%
arrange(desc(Similarity)) %>%
head(5) %>%
mutate(
occupation = fct_reorder(
.f = occupation
, .x = Similarity
, .fun = max
, .desc = F
)
, career_cluster = factor(career_cluster)
) %>%
ggplot(aes(
y = Similarity
, x = occupation
, fill = career_cluster
)) +
geom_col() +
labs(
y = 'Similarity (%)'
, x = NULL
, title = NULL
, fill = 'Career Cluster'
) +
scale_y_continuous(limits = c(-1,1)) +
scale_x_discrete(
labels = function(x){str_wrap(x, width = 22)}
) +
ggthemes::scale_fill_gdocs() +
ggthemes::theme_tufte() +
theme(
legend.position = 'bottom'
, legend.direction = 'vertical'
, legend.title.align = 0.5
)
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(message = F)
pkg <- c(
'FNN' #Fast K-NN Algorithm (faster than the 'class' package)
, 'jsonify' #Work with JSON (faster than jsonlite)
, 'ggthemes', 'viridis', 'patchwork' #Data visualization
, 'tidyverse', 'glue' #Data wrangling
, 'tinytex' #LaTeX
# , 'kableExtra' #LaTeX
)
# Activate / install packages
lapply(pkg, function(x)
if(!require(x, character.only = T))
{install.packages(x); require(x)})
# Install TinyTex
if(!tinytex::is_tinytex()){
tinytex::install_tinytex()
}
# Increase buffer size
# Sys.setenv("VROOM_CONNECTION_SIZE" = 10000000)
# Package citation
# lapply(pkg, function(x)
#   {citation(package = x)})
df_KNN.output %>%
mutate(
occupation = fct_reorder(
.f = occupation
, .x = Similarity
, .fun = max
, .desc = F
)
) %>%
ggplot(aes(
x = occupation
, y = Similarity
)) +
geom_line(
color = viridis::plasma(1)
, size = 1.22
) +
geom_hline(
yintercept = 0
, color = '#001219'
) +
labs(
x = 'Similarity Ranking'
, y = 'Similarity (%)'
, title = NULL
) +
scale_y_continuous(limits = c(-1,1)) +
ggthemes::theme_tufte() +
theme(
axis.text.x = element_blank()
, axis.ticks.x = element_blank()
) -> plt_line
lapply(
list_factors
, function(scales){
psych::scoreVeryFast(
keys = scales
, items = df_input
, totals = F #Average scores
) %>%
as_tibble() %>%
colMeans()
}
) %>%
flatten_df() -> df_factor.scores
list_skill.factors <- list(
'Discernment' = c(
# Factor 1 is composed of cognitive, non-technical, general competencies related to decision-making (discernment)
'judgment_and_decision.l'
, 'active_learning.l'
, 'complex_problem_solving.l'
, 'critical_thinking.l'
)
, 'Technical' = c(
# Factor 2 is composed of mechanical, hands-on, specialist skills (technical)
'equipment_selection.l'
, 'troubleshooting.l'
, 'repairing.l'
, 'equipment_maintenance.l'
)
)
list_skill.factors <- list(
'Discernment' = c(
# Factor 1 is composed of cognitive, non-technical, general competencies related to decision-making (discernment)
'judgment_and_decision.l'
, 'active_learning.l'
, 'complex_problem_solving.l'
, 'critical_thinking.l'
)
, 'Technical' = c(
# Factor 2 is composed of mechanical, hands-on, specialist skills (technical)
'equipment_selection.l'
, 'troubleshooting.l'
, 'repairing.l'
, 'equipment_maintenance.l'
)
)
list_ablt.factors <- list(
'Perception' = c(
# Factor 1 is composed of perceptual abilities (perception):
'glare_sensitivity.l'
, 'peripheral_vision.l'
, 'sound_localization.l'
)
, 'Dexterity' = c(
# Factor 2 is composed of manual abilities (dexterity):
'arm_hand_steadiness.l'
, 'finger_dexterity.l'
, 'control_precision.l'
)
, 'Intelligence' = c(
# Factor 4 is composed of cognitive abilities (intelligence):
'inductive_reasoning.l'
, 'deductive_reasoning.l'
, 'information_ordering.l'
)
)
list_know.factors <- list(
'Health' = c(
# Factor 1 is composed of health-related fields of knowledge (health).
'therapy_and_counseling.l'
, 'medicine_and_dentistry.l'
, 'psychology.l'
, 'biology.l'
)
, 'Building' = c(
# Factor 2 is composed of engineering / building-related fields of knowledge (building).
'physics.l'
, 'engineering_and_technology.l'
, 'mechanical.l'
, 'building_and_construction.l'
)
, 'Business' = c(
# Factor 3 is composed of financial and enterprising fields of knowledge (business).
'administration_and_management.l'
, 'economics_and_accounting.l'
, 'personnel_and_human_resources.l'
, 'administrative.l'
)
, 'Arts_Humanities' = c(
# Factor 4 is composed of arts and humanities (arts & humanities).
'history_and_archeology.l'
, 'fine_arts.l'
, 'philosophy_and_theology.l'
, 'sociology_and_anthropology.l'
)
)
list_factors <- list(
'Skills' = list_skill.factors
, 'Abilities' = list_ablt.factors
, 'Knowledge' = list_know.factors
)
list_factors
list_factors %>% bind_rows(.id = 'Competency')
list_factors %>% bind_rows(.id = 'Competency') %>% pivot_longer()
list_factors %>% bind_rows(.id = 'Competency') %>% pivot_longer(cols = -Competency)
list_factors %>% bind_rows(.id = 'Competency') %>% pivot_longer(cols = -Competency) %>% drop_na()
list_factors %>% bind_rows(.id = 'Competency') %>% pivot_longer(cols = -Competency) %>% drop_na() %>% view()
list_factors %>% bind_rows(.id = 'competency') %>% pivot_longer(cols = -competency) %>% group_by(competency)
list_factors %>% bind_rows(.id = 'competency') %>% pivot_longer(cols = -competency) %>% drop_na() %>% group_by(competency) %>%
ds
list_factors %>% bind_rows(.id = 'competency') %>% pivot_longer(cols = -competency) %>% drop_na() %>% group_by(competency)
list_factors %>% bind_rows(.id = 'competency') %>% pivot_longer(cols = -competency) %>% drop_na() %>% group_by(competency) %>% group_by(competency) %>% summarise(unique(name))
list_factors %>% bind_rows(.id = 'competency') %>% pivot_longer(cols = -competency) %>% drop_na() %>% group_by(competency) %>% group_by(competency) %>% name = summarise(unique(name))
list_factors %>% bind_rows(.id = 'competency') %>% pivot_longer(cols = -competency) %>% drop_na() %>% group_by(competency) %>% group_by(competency) %>% summarise(name = unique(name))
list_factors %>%
bind_rows(
.id = 'competency'
) %>%
pivot_longer(
cols = -competency
) %>%
drop_na() %>%
group_by(competency) %>%
summarise(
name = unique(name)
)
list_factors %>%
bind_rows(
.id = 'competency'
) %>%
pivot_longer(
cols = -competency
) %>%
drop_na() %>%
group_by(competency) %>%
summarise(
name = unique(name)
) -> df_factors.names
df_factors.names
```{r factor.scores, include=TRUE}
lapply(
list_factors
, function(scales){
psych::scoreVeryFast(
keys = scales
, items = df_input
, totals = F #Average scores
) %>%
as_tibble() %>%
colMeans()
}
) %>%
flatten_df() -> df_factor.scores
# User questionnaires data frame
df_input <- readr::read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSphzWoCxoNaiaJcQUWKCMqUAT041Q8UqUgM7rSzIwYZb7FhttKJwNgtrFf-r7EgzXHFom4UjLl2ltk/pub?gid=725827850&single=true&output=csv')
# Selected respondent
chr_user <- 'Martijn'
# chr_user <- 'Cao'
df_input %>%
filter(Name == chr_user) %>%
select(-Name) -> df_input
df_input %>%
select(
all_of(
list_factors %>%
flatten() %>%
flatten_chr()
)
) %>%
mutate(
across(
.cols = all_of(
list_factors %>%
flatten() %>%
flatten_chr()
)
, .fns = function(x){
recode(x
, '1' = .0
, '2' = .25
, '3' = .5
, '4' = .75
, '5' = 1
)}
)
) -> df_input
lapply(
list_factors
, function(scales){
psych::scoreVeryFast(
keys = scales
, items = df_input
, totals = F #Average scores
) %>%
as_tibble() %>%
colMeans()
}
) %>%
flatten_df() -> df_factor.scores
df_factor.scores
df_factor.scores %>%
pivot_longer(
cols = everything()
)
df_factor.scores %>%
pivot_longer(
cols = everything()
) %>%
full_join(
df_factors.names
)
df_factor.scores
lapply(
list_factors
, function(scales){
psych::scoreVeryFast(
keys = scales
, items = df_input
, totals = F #Average scores
) %>%
as_tibble() %>%
colMeans()
}
) %>%
flatten_df() -> df_factor.scores
df_factor.scores %>%
pivot_longer(
cols = everything()
) %>%
full_join(
df_factors.names
) -> df_factor.scores
df_factor.scores
?geom_text
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
pkg <- c(
'FNN' #Fast K-NN Algorithm (faster than the 'class' package)
, 'jsonify' #Work with JSON (faster than jsonlite)
, 'ggthemes', 'viridis', 'patchwork' #Data visualization
, 'tidyverse', 'glue' #Data wrangling
, 'tinytex' #LaTeX
# , 'kableExtra' #LaTeX
)
# Activate / install packages
lapply(pkg, function(x)
if(!require(x, character.only = T))
{install.packages(x); require(x)})
# Install TinyTex
if(!tinytex::is_tinytex()){
tinytex::install_tinytex()
}
# Increase buffer size
# Sys.setenv("VROOM_CONNECTION_SIZE" = 10000000)
# Package citation
# lapply(pkg, function(x)
#   {citation(package = x)})
df_factor.scores %>%
mutate(
name = fct_reorder(name, value)
) %>%
ggplot(aes(
x = name
, y = value
, fill = competency
, label = scales::percent(value)
)) +
geom_col() +
geom_text(aes(color = competency)
, position = position_dodge(width = 0.9)
, vjust = -0.25
, size = 3
) +
guides(
fill = guide_legend(title.position = 'top')
, color = 'none'
) +
labs(
x = 'Factor'
, y = 'Factor Score'
, title = NULL
, fill = 'Competency'
) +
scale_x_discrete(
labels = function(x){str_wrap(x,10)}
) +
scale_y_continuous(
limits = c(0,1)
, labels = scales::percent_format()
) +
ggthemes::scale_fill_gdocs() +
ggthemes::scale_color_gdocs() +
ggthemes::theme_tufte() +
theme(
legend.position = 'bottom'
# , legend.direction = 'vertical'
, legend.title.align = 0.5
)
