pivot_longer(
cols = -1
, names_to = 'Item'
, values_to = 'Value'
) %>%
pivot_wider(
names_from = Item
, values_from = Value
)
df_occupations %>%
select(
Occupation
, ends_with('.L')
) %>%
pivot_longer(
cols = -1
, names_to = 'Item'
, values_to = 'Value'
)
df_occupations %>%
select(
Occupation
, ends_with('.L')
) %>%
pivot_longer(
cols = -1
, names_to = 'Item'
, values_to = 'Value'
) %>%
pivot_wider(
names_from = Item
, values_from = Value
)
df_occupations %>%
select(
Occupation
, ends_with('.L')
) %>%
pivot_longer(
cols = -1
, names_to = 'Item'
, values_to = 'Value'
)
df_occupations %>%
select(
Occupation
, ends_with('.L')
) %>%
pivot_longer(
cols = -'Occupation'
, names_to = 'Item'
, values_to = 'Value'
)
df_occupations %>%
select(
Occupation
, ends_with('.L')
) %>%
pivot_longer(
cols = -'Occupation'
, names_to = 'Item'
, values_to = 'Value'
) %>%
pivot_wider(
names_from = Occupation
, values_from = Value
)
df_occupations %>%
select(
Occupation
, ends_with('.L')
) %>%
pivot_longer(
cols = -'Occupation'
, names_to = 'Item'
, values_to = 'Value'
) %>%
pivot_wider(
names_from = Occupation
, values_from = Value
) %>%
select(where(is.numeric))
df_occupations %>%
select(
Occupation
, ends_with('.L')
) %>%
pivot_longer(
cols = -'Occupation'
, names_to = 'Item'
, values_to = 'Value'
) %>%
pivot_wider(
names_from = Occupation
, values_from = Value
) %>%
select(where(is.numeric)) %>%
mutate(#0 to 100 => 0 to 1 (helps calculate similarity later on)
across(
.fns = function(x){x/100}
)
) -> df_occupations.numeric.pivot
df_occupations.numeric.pivot
df_occupations %>%
select(
Occupation
, ends_with('.L')
) %>%
pivot_longer(
cols = -'Occupation'
, names_to = 'Item'
, values_to = 'Value'
)
# GLOBAL EFA PAREMETERS ---------------------------------------------------
# Number of factors
auto_select.nfactors <- T
# int_nfactors.min <- 1
# int_nfactors.max <- 5
# Minimum factor size
int_min.factor_size.basic <- 2
int_min.factor_size <- 3
# Top items
int_n.items.total.basic <- 5
int_n.items.total.cross <- 10
int_n.items.total.skill <- 15
int_n.items.total.ablt <- 20
int_n.items.total.know <- 15
# Rotation (Oblique)
chr_rotation <- 'promax'
# chr_rotation <- 'oblimin'
# chr_rotation <- 'varimax'
# Underloadings and crossloadings
remove_under_loading.items <- F
remove_cross_loading.items <- T
dbl_under_loading.threshold <- 0.4 #Lesser than 0.4 loading <- under loading
# dbl_cross_loading.threshold <- 0.05 #Lesser than 0.05 loading difference <- cross loading
dbl_cross_loading.threshold <- 0.25
# Diagrams and tests
show_diagrams <- T
show_results <- F
auto_select.nfactors
int_nfactors.min
int_nfactors.max
int_min.factor_size
int_n.items.total.skill
nrow(df_occupations.numeric.pivot)
ncol(df_occupations.numeric.pivot)
chr_rotation
remove_under_loading.items
remove_cross_loading.items
dbl_under_loading.threshold
dbl_cross_loading.threshold
# TEST --------------------------------------------------------------------
fun_best.model.multi.workflow(
# Basic
df_data.numeric = df_occupations.numeric.pivot
, auto_select.nfactors = auto_select.nfactors
, int_nfactors.min = int_nfactors.min
, int_nfactors.max = int_nfactors.max
, int_min.factor_size = 10
, int_n.items.total = ncol(df_occupations.numeric.pivot)
, chr_rotation = chr_rotation
# Underloadings and crossloadings
, remove_under_loading.items = remove_under_loading.items
, remove_cross_loading.items = remove_cross_loading.items
, dbl_under_loading.threshold = dbl_under_loading.threshold
, dbl_cross_loading.threshold = dbl_cross_loading.threshold
# Diagrams and tests
, show_diagrams = show_diagrams
, show_results = show_results
) -> dsds
fun_adequacy.tests(df_occupations.numeric.pivot)
df_occupations.numeric.pivot
cor(df_occupations.numeric.pivot)
fun_adequacy.tests(cor(df_occupations.numeric.pivot))
.125*2
0.25 + 0.125
0.375 + 0.125
0.5 + .125
0.5 + .125
0.625 + .125
.75 + .125
df_occupations %>%
select(
all_of(c(# Selected skills, abilities, and knowledge
# df_skills.items$Item
# , df_ablt.items$Item
# where(function(x){str_detect(attributes(x)$label, '_Skills.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Abilities.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Knowledge.')}) #Skills only
# , -ends_with('.I') #Using recommended levels
# , df_know.items$Item
chr_Skill.Items
, chr_Ablt.Items
, chr_Know.Items
)
)
) %>%
mutate(#0 to 100 => 0 to 1 (helps calculate similarity later on)
across(
.fns = function(x){x/100}
)
, across(
.fns = function(x){
case_when(
x < 0.125 ~ 0
, x > 0.125 & x <= 0.375 ~ 0.25
, x > 0.375 & x <= 0.625 ~ 0.5
, x > 0.625 & x <= .875 ~ 0.75
, x > .875 ~ 1
)
}
)
)
df_occupations %>%
select(
all_of(c(# Selected skills, abilities, and knowledge
# df_skills.items$Item
# , df_ablt.items$Item
# where(function(x){str_detect(attributes(x)$label, '_Skills.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Abilities.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Knowledge.')}) #Skills only
# , -ends_with('.I') #Using recommended levels
# , df_know.items$Item
chr_Skill.Items
, chr_Ablt.Items
, chr_Know.Items
)
)
) %>%
mutate(#0 to 100 => 0 to 1 (helps calculate similarity later on)
across(
.fns = function(x){x/100}
)
)
df_occupations %>%
select(
all_of(c(# Selected skills, abilities, and knowledge
# df_skills.items$Item
# , df_ablt.items$Item
# where(function(x){str_detect(attributes(x)$label, '_Skills.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Abilities.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Knowledge.')}) #Skills only
# , -ends_with('.I') #Using recommended levels
# , df_know.items$Item
chr_Skill.Items
, chr_Ablt.Items
, chr_Know.Items
)
)
) %>%
mutate(#0 to 100 => 0 to 1 (helps calculate similarity later on)
across(
.fns = function(x){x/100}
)
, across(
.fns = function(x){
case_when(
x < 0.125 ~ 0
, x > 0.125 & x <= 0.375 ~ 0.25
, x > 0.375 & x <= 0.625 ~ 0.5
, x > 0.625 & x <= .875 ~ 0.75
, x > .875 ~ 1
)
}
)
)
# Only numeric variables
df_occupations %>%
select(
all_of(c(# Selected skills, abilities, and knowledge
# df_skills.items$Item
# , df_ablt.items$Item
# where(function(x){str_detect(attributes(x)$label, '_Skills.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Abilities.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Knowledge.')}) #Skills only
# , -ends_with('.I') #Using recommended levels
# , df_know.items$Item
chr_Skill.Items
, chr_Ablt.Items
, chr_Know.Items
)
)
) %>%
mutate(#0 to 100 => 0 to 1 (helps calculate similarity later on)
across(
.fns = function(x){x/100}
)
, across(
.fns = function(x){
case_when(
x < 0.125 ~ 0
, x > 0.125 & x <= 0.375 ~ 0.25
, x > 0.375 & x <= 0.625 ~ 0.5
, x > 0.625 & x <= .875 ~ 0.75
, x > .875 ~ 1
)
}
)
) -> df_occupations.numeric.items
# SIMULATED QUESTIONNAIRE ---------------------------------------------------------------
# Set number of individuals
n_simulations <- 1000
# Generic names for each individual
chr_individuals <- paste('Subject', 1:n_simulations)
names(chr_individuals) <- chr_individuals
# Get the first line from the correlation matrix
# In order to keep the original relationship between variables
df_occupations.numeric.items %>%
cov() -> cov_mat
df_occupations.numeric.items %>%
cor() %>%
as_tibble() %>%
slice(1) -> df_correlations
# Simulate normal distributions in accordance with the correlation matrix
# Mean for each variable
df_occupations.numeric.items %>%
summarise(across(
.fns = mean
)) %>%
as.numeric() -> dbl_mean
# Multivariate truncated normal distribution
rtmvnorm(
n = n_simulations
, mu = dbl_mean
, sigma = cov_mat
, lb = rep(0,length(dbl_mean)) #Scale between 0 and 1
, ub = rep(1,length(dbl_mean)) #Scale between 0 and 1
) -> mat_trunc_norm
colnames(mat_trunc_norm) <- colnames(df_occupations.numeric.items)
mat_trunc_norm %>%
as_tibble() -> df_simulations
# Add the names of each individual
df_simulations %>%
mutate(
Subject = chr_individuals
, .before = names(.)[1]
) -> df_simulations
df_simulations
# Only numeric variables
df_occupations %>%
select(
all_of(c(# Selected skills, abilities, and knowledge
# df_skills.items$Item
# , df_ablt.items$Item
# where(function(x){str_detect(attributes(x)$label, '_Skills.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Abilities.')}) #Skills only
# , where(function(x){str_detect(attributes(x)$label, 'Knowledge.')}) #Skills only
# , -ends_with('.I') #Using recommended levels
# , df_know.items$Item
chr_Skill.Items
, chr_Ablt.Items
, chr_Know.Items
)
)
) %>%
mutate(#0 to 100 => 0 to 1 (helps calculate similarity later on)
across(
.fns = function(x){x/100}
)
) -> df_occupations.numeric.items
df_occupations.numeric.items
# SIMULATED QUESTIONNAIRE ---------------------------------------------------------------
# Set number of individuals
n_simulations <- 1000
# Generic names for each individual
chr_individuals <- paste('Subject', 1:n_simulations)
names(chr_individuals) <- chr_individuals
# Get the first line from the correlation matrix
# In order to keep the original relationship between variables
df_occupations.numeric.items %>%
cov() -> cov_mat
df_occupations.numeric.items %>%
cor() %>%
as_tibble() %>%
slice(1) -> df_correlations
# Simulate normal distributions in accordance with the correlation matrix
# Mean for each variable
df_occupations.numeric.items %>%
summarise(across(
.fns = mean
)) %>%
as.numeric() -> dbl_mean
# Multivariate truncated normal distribution
rtmvnorm(
n = n_simulations
, mu = dbl_mean
, sigma = cov_mat
, lb = rep(0,length(dbl_mean)) #Scale between 0 and 1
, ub = rep(1,length(dbl_mean)) #Scale between 0 and 1
) -> mat_trunc_norm
colnames(mat_trunc_norm) <- colnames(df_occupations.numeric.items)
mat_trunc_norm %>%
as_tibble() -> df_simulations
# Add the names of each individual
df_simulations %>%
mutate(
Subject = chr_individuals
, .before = names(.)[1]
# ) -> df_simulations
) %>%
mutate(
across(
.fns = function(x){
case_when(
x < 0.125 ~ 0
, x > 0.125 & x <= 0.375 ~ 0.25
, x > 0.375 & x <= 0.625 ~ 0.5
, x > 0.625 & x <= .875 ~ 0.75
, x > .875 ~ 1
)
}
)
) -> df_simulations
df_simulations
mat_trunc_norm %>%
as_tibble() -> df_simulations
df_simulations
colnames(mat_trunc_norm) <- colnames(df_occupations.numeric.items)
df_simulations
# Add the names of each individual
df_simulations %>%
mutate(
Subject = chr_individuals
, .before = names(.)[1]
# ) -> df_simulations
) %>%
mutate(
across(
.cols = -Subject
, .fns = function(x){
case_when(
x < 0.125 ~ 0
, x > 0.125 & x <= 0.375 ~ 0.25
, x > 0.375 & x <= 0.625 ~ 0.5
, x > 0.625 & x <= .875 ~ 0.75
, x > .875 ~ 1
)
}
)
) -> df_simulations
df_simulations
# COMPLETE COMPARISON
# Or find k nearest neighbors using the whole data set
# i.e. order everything with respect to euclidean distance
k.value <- nrow(df_occupations.numeric.items)
# Find the k nearest neighbors
lapply(
chr_individuals
, function(subject){
df_simulations %>%
filter(Subject == subject) -> df_subject
FNN::get.knnx(
data = df_occupations.numeric.items
, query = df_subject %>% select(where(is.numeric))
, k = k.value
) -> KNN.output
# Arrange original data frame with KNN output
df_occupations %>%
slice(as.vector(KNN.output$nn.index)) %>%
select(#For the present purposes, keep only the following columns
Career_Cluster
, Occupation
, Annual_Wage_2021
# , df_loadings.items.skills_ablts$Metric
) %>%
# plyr::rbind.fill(df_subject) %>%
mutate(#Add euclidean distances and convert them to similarities
Euclidean_Distance = as.vector(KNN.output$nn.dist)
# Common similarity: 1/(1 + dist), "+1" for dist = 0
, Similarity.Common = 1 / (1 + Euclidean_Distance)
# Similarity via gaussian kernel: exp(-dist)
, Similarity.Gaussian = exp(-Euclidean_Distance)
# Normalized by max value: 1 - dist.norm = 1 - dist/max(dist)
, Similarity.Max = 1 - (Euclidean_Distance / max(Euclidean_Distance))
# [Try again] Yielding negative values for greater distances
# Tangent similarity: 1 - arctan(dist) = 1 for dist = 0
# , Similarity.Tan = 1 - atan(Euclidean_Distance)
# , Similarity.Tan = 1 - atan(Euclidean_Distance/2)
# , Similarity.Tan = 1 - atan(Euclidean_Distance/pi)
# [Try again] Equivalence between euclidean and cosine
# [Wrong formula] Yielding negative values for greater distances
# , Similarity.Cosine = 1 - (Euclidean_Distance/2)
# , Similarity.Cosine = 1 - (Euclidean_Distance^2)/2
# Wage difference for later on
, Wage.Diff = Annual_Wage_2021 - first(Annual_Wage_2021)
# ) %>%
# mutate(#Round values
#   across(
#     .cols = starts_with('Similarity.')
#     ,.fns = function(x){round(x,4)}
#   )
# ) -> df_occupations.KNN
) -> df_occupations.KNN
return(df_occupations.KNN)
}
) -> list_df_occupations.KNN
list_df_occupations.KNN %>%
bind_rows() -> test
test %>%
pivot_longer(
cols = starts_with('Similarity.')
, names_to = 'Similarity'
, values_to = 'Value'
) %>%
ggplot(aes(
x = Value
, color = Similarity
)) +
geom_density(size = 1.5)
test$Similarity.Common %>% summary()
test$Similarity.Gaussian %>% summary()
